{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create csv file for sales, purchases and inventory of products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datalabframework as dlf\n",
    "import pandas as pd\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting engine and loading fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_engine():\n",
    "    project = dlf.project.load()\n",
    "    return project.engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = start_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dlf:{'md': {'hash': '0x1c79e1ac5aa3d533', 'url': 'hdfs://bigdata-m.teko.vn:18020/teko/prod/etl/fact/fact_table', 'service': 'hdfs', 'format': 'parquet', 'host': 'bigdata-m.teko.vn', 'port': 18020, 'driver': None, 'database': None, 'username': None, 'password': None, 'resource_path': 'fact_table', 'provider_path': '/teko/prod/etl/fact', 'provider_alias': 'fact', 'resource_alias': 'fact_table', 'cache': None, 'date_column': None, 'date_start': None, 'date_end': None, 'date_window': None, 'date_partition': None, 'update_column': None, 'hash_column': None, 'state_column': None, 'options': {}, 'mapping': {}}, 'mode': None, 'records': 5401350, 'columns': 96, 'time': 14.03477175347507, 'time_core': 7.699648783542216, 'time_prep': 6.335121406242251}\n"
     ]
    }
   ],
   "source": [
    "df = engine.load(\"fact_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting transactions and fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = df.select('transaction_date', 'sku_id', 'sku_name', 'doc_type',\n",
    "                         'quantity', 'warehouse_id', 'end_day_quantity') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+--------------------+--------+--------+------------+----------------+\n",
      "|transaction_date| sku_id|            sku_name|doc_type|quantity|warehouse_id|end_day_quantity|\n",
      "+----------------+-------+--------------------+--------+--------+------------+----------------+\n",
      "|      2019-02-28|1206838|phí dịch vụ giao ...|     PTX|  1.0000|      090016|        335.0000|\n",
      "|      2019-02-28|1809570|smart tivi lg 55 ...|     PTX| 16.0000|      090016|          0.0000|\n",
      "|      2019-02-28|1808441|khung treo nghiên...|     PTX| 16.0000|      090016|          0.0000|\n",
      "|      2019-02-28|1810247|máy tính xách tay...|     PTX|  1.0000|        0201|          0.0000|\n",
      "|      2019-02-28|1704995|chuột fuhlen l102...|     PTX|  5.0000|      091001|          0.0000|\n",
      "|      2019-02-28|1206838|phí dịch vụ giao ...|     PTX|  1.0000|      091001|       7736.0000|\n",
      "|      2019-02-28|1703670|bàn phím cơ dareu...|     PTX|  1.0000|        0601|          8.0000|\n",
      "|      2019-02-28|1703944|chuột máy tính be...|     PTX|  1.0000|        0201|          1.0000|\n",
      "|      2019-02-28|1206838|phí dịch vụ giao ...|     PTX|  1.0000|        0201|       2802.0000|\n",
      "|      2019-02-28|1601383|màn hình lcd sams...|     PTX|  1.0000|        2001|          0.0000|\n",
      "+----------------+-------+--------------------+--------+--------+------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing transaction date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_date = transactions.select('transaction_date').distinct().orderBy('transaction_date').collect()\n",
    "columns = [row.transaction_date for row in transaction_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating sales products pivot table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting sale transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = transactions.select('transaction_date', 'sku_id', 'quantity').filter((transactions.doc_type == 'PTX') | (transactions.doc_type == 'HDF')) \\\n",
    ".groupby('transaction_date', 'sku_id').agg(F.sum('quantity').alias('sell_quantity'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+-------------+\n",
      "|transaction_date| sku_id|sell_quantity|\n",
      "+----------------+-------+-------------+\n",
      "|      2017-01-01|1601431|       1.0000|\n",
      "|      2017-01-01|1603841|       1.0000|\n",
      "|      2017-01-01|1402753|       1.0000|\n",
      "|      2017-01-01|1602867|       3.0000|\n",
      "|      2017-01-01|1302572|      27.0000|\n",
      "|      2017-01-01|1201142|       1.0000|\n",
      "|      2017-01-01|1601555|       5.0000|\n",
      "|      2017-01-01|1601619|       2.0000|\n",
      "|      2017-01-01|1203604|       1.0000|\n",
      "|      2017-01-01|1502689|       1.0000|\n",
      "|      2017-01-01|1200869|       1.0000|\n",
      "|      2017-01-01|1200870|       1.0000|\n",
      "|      2017-01-01|1601780|      26.0000|\n",
      "|      2017-01-01|1402437|       1.0000|\n",
      "|      2017-01-01|1601291|       2.0000|\n",
      "|      2017-01-01|1601632|       1.0000|\n",
      "|      2017-01-01|1600817|       1.0000|\n",
      "|      2017-01-01|1603017|       1.0000|\n",
      "|      2017-01-01|1207133|       3.0000|\n",
      "|      2017-01-01|1204495|       3.0000|\n",
      "+----------------+-------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales.orderBy('transaction_date').show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "| sku_id|sell_quantity|\n",
      "+-------+-------------+\n",
      "|1807457|       9.0000|\n",
      "+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales.select('sku_id', 'sell_quantity').filter((sales.transaction_date == '2018-09-30') & (sales.sku_id == 1807457)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating pivot table by transaction_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = sales.groupBy('sku_id').pivot('transaction_date', columns).sum('sell_quantity').orderBy('sku_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = sales_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+\n",
      "| sku_id|2018-06-01|2018-06-02|\n",
      "+-------+----------+----------+\n",
      "|1200010|    0.0000|    0.0000|\n",
      "|1200108|    0.0000|    0.0000|\n",
      "|1200109|    0.0000|    4.0000|\n",
      "|1200110|    0.0000|    1.0000|\n",
      "|1200111|    0.0000|    0.0000|\n",
      "|1200112|    0.0000|    0.0000|\n",
      "|1200113|    3.0000|    5.0000|\n",
      "|1200114|    1.0000|    0.0000|\n",
      "|1200118|    0.0000|    0.0000|\n",
      "|1200119|    4.0000|    2.0000|\n",
      "|1200122|    2.0000|    3.0000|\n",
      "|1200124|    0.0000|    0.0000|\n",
      "|1200125|    0.0000|    0.0000|\n",
      "|1200131|    0.0000|    0.0000|\n",
      "|1200132|    0.0000|    1.0000|\n",
      "|1200133|    0.0000|    0.0000|\n",
      "|1200135|    0.0000|    0.0000|\n",
      "|1200137|    0.0000|    0.0000|\n",
      "|1200138|    1.0000|    1.0000|\n",
      "|1200140|    0.0000|    0.0000|\n",
      "+-------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df.select('sku_id', '2018-06-01', '2018-06-02').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.toPandas().to_csv('sales_1.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating purchases products pivot table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting purchase transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchases = transactions.select('transaction_date', 'sku_id', 'quantity').filter(transactions.doc_type == 'PNA') \\\n",
    ".groupby('transaction_date', 'sku_id').agg(F.sum('quantity').alias('buy_quantity'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+------------+\n",
      "|transaction_date| sku_id|buy_quantity|\n",
      "+----------------+-------+------------+\n",
      "|      2017-01-01|1204071|     30.0000|\n",
      "|      2017-01-01|1500184|      8.0000|\n",
      "|      2017-01-01|1204075|      1.0000|\n",
      "|      2017-01-01|1204077|     13.0000|\n",
      "|      2017-01-01|1204070|     96.0000|\n",
      "|      2017-01-01|1300888|      1.0000|\n",
      "|      2017-01-01|1301401|     68.0000|\n",
      "|      2017-01-01|1300886|    131.0000|\n",
      "|      2017-01-01|1204072|      1.0000|\n",
      "|      2017-01-02|1203021|      5.0000|\n",
      "|      2017-01-02|1301199|      1.0000|\n",
      "|      2017-01-02|1404738|      5.0000|\n",
      "|      2017-01-02|1203128|      2.0000|\n",
      "|      2017-01-02|1503187|      2.0000|\n",
      "|      2017-01-02|1302625|      2.0000|\n",
      "|      2017-01-02|1601032|      2.0000|\n",
      "|      2017-01-02|1203022|      3.0000|\n",
      "|      2017-01-02|1602156|      2.0000|\n",
      "|      2017-01-02|1400700|      5.0000|\n",
      "|      2017-01-02|1203052|      5.0000|\n",
      "+----------------+-------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "purchases.orderBy('transaction_date').show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchases_df = purchases.groupBy('sku_id').pivot('transaction_date', columns).sum('buy_quantity').orderBy('sku_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchases_df = purchases_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|2018-06-01|2018-06-02|\n",
      "+----------+----------+\n",
      "|    0.0000|    0.0000|\n",
      "|    0.0000|    0.0000|\n",
      "|    0.0000|    0.0000|\n",
      "|    0.0000|    0.0000|\n",
      "|    0.0000|    0.0000|\n",
      "|   10.0000|    0.0000|\n",
      "|    5.0000|    0.0000|\n",
      "|    0.0000|    0.0000|\n",
      "|    3.0000|    0.0000|\n",
      "|    0.0000|    0.0000|\n",
      "|    0.0000|    0.0000|\n",
      "|    0.0000|    0.0000|\n",
      "|    0.0000|    0.0000|\n",
      "|    5.0000|    0.0000|\n",
      "|    0.0000|    0.0000|\n",
      "|    0.0000|    0.0000|\n",
      "|    0.0000|    0.0000|\n",
      "|    0.0000|    0.0000|\n",
      "|    0.0000|    0.0000|\n",
      "|    0.0000|    0.0000|\n",
      "+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "purchases_df.select('sku_id', '2018-06-01', '2018-06-02').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchases_df.toPandas().to_csv('purchases.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating inventory pivot table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping duplicate transactions of sku_id in same day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_distinct = transactions.select('transaction_date', 'sku_id', 'warehouse_id', 'end_day_quantity').distinct().orderBy('transaction_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3008254"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_distinct.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating number of inventory of each sku_id by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_inventory(date):\n",
    "    date = pd.to_datetime(date).date()\n",
    "    transactions_before_date = transactions_distinct.filter(F.col('transaction_date') <= date)\n",
    "    windowSpec = Window.partitionBy('warehouse_id', 'sku_id').orderBy(F.desc('transaction_date'))\n",
    "    tmp_df = transactions_before_date.select('sku_id', 'warehouse_id', 'end_day_quantity', F.rank().over(windowSpec).alias('rank')).where('rank == 1')\n",
    "    res = tmp_df.groupby('sku_id').agg(F.sum('end_day_quantity').alias('num_inventory'))\n",
    "    res = res.withColumn('transaction_date', F.lit(date))\n",
    "    return res.select('transaction_date', 'sku_id', 'num_inventory')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing for a specific date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "838"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_inventory('2017-01-01').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an empty dataframe to append data of each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "sc = spark.sparkContext\n",
    "\n",
    "field = [StructField(\"transaction_date\", TimestampType(), True), StructField(\"sku_id\", IntegerType(), True), StructField(\"num_inventory\", DoubleType(), True)]\n",
    "schema = StructType(field)\n",
    "\n",
    "inventory_df = spark.createDataFrame(sc.emptyRDD(), schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating to calculate number of inventory of each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-01\n",
      "2017-02-01\n",
      "2017-03-01\n",
      "2017-04-01\n",
      "2017-05-01\n",
      "2017-06-01\n",
      "2017-07-01\n",
      "2017-08-01\n",
      "2017-09-01\n",
      "2017-10-01\n",
      "2017-11-01\n",
      "2017-12-01\n",
      "2018-01-01\n",
      "2018-02-01\n",
      "2018-03-01\n",
      "2018-04-01\n",
      "2018-05-01\n",
      "2018-06-01\n",
      "2018-07-01\n",
      "2018-08-01\n",
      "2018-09-01\n",
      "2018-10-01\n",
      "2018-11-01\n",
      "2018-12-01\n",
      "2019-01-01\n",
      "2019-02-01\n",
      "2019-03-01\n"
     ]
    }
   ],
   "source": [
    "for row in transaction_date:\n",
    "    if row.transaction_date > date(2018, 12, 22):\n",
    "        num_inventory(row.transaction_date).toPandas().to_csv('inventory_df_append.csv', index = False, header = False, mode = 'a')\n",
    "    if row.transaction_date.day == 1:\n",
    "        print(row.transaction_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "transaction_date[0].transaction_date <= date(2017, 1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_pd_df = pd.read_csv('inventory_df_append.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_df_pivot = inventory_pd_df.pivot_table(values = 'num_inventory', index = ['sku_id'], columns = ['transaction_date'], aggfunc=np.sum, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_df_pivot.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_df_pivot = inventory_df_pivot.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_id</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <th>2017-01-02</th>\n",
       "      <th>2017-01-03</th>\n",
       "      <th>2017-01-04</th>\n",
       "      <th>2017-01-05</th>\n",
       "      <th>2017-01-06</th>\n",
       "      <th>2017-01-07</th>\n",
       "      <th>2017-01-08</th>\n",
       "      <th>2017-01-09</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1200109</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1200110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1200111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1200112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1200113</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1200114</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1200118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1200119</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sku_id  2017-01-01  2017-01-02  2017-01-03  2017-01-04  2017-01-05  \\\n",
       "0  1200010           0           0           0           0           0   \n",
       "1  1200108           0           0           0           0           1   \n",
       "2  1200109           0           7           7           7          14   \n",
       "3  1200110           0           0           4           4           6   \n",
       "4  1200111           0           0           0           0           0   \n",
       "5  1200112           0           0           0           0           0   \n",
       "6  1200113           0           1           9          14          23   \n",
       "7  1200114           0           4           5           5          16   \n",
       "8  1200118           0           0           0           0           0   \n",
       "9  1200119           0           4           9           7          18   \n",
       "\n",
       "   2017-01-06  2017-01-07  2017-01-08  2017-01-09  \n",
       "0           0           0           0           0  \n",
       "1           1           1           1           1  \n",
       "2          14          13          11          14  \n",
       "3           6           6           6           8  \n",
       "4           0           0           0           0  \n",
       "5           0           0           0           0  \n",
       "6          20          18          13          24  \n",
       "7          15          15          15          13  \n",
       "8           0           0           0           0  \n",
       "9          17          17          17          17  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inventory_df_pivot.iloc[:10, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_df_pivot.to_csv('inventory.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
